# Concept Explorer - LLM Configuration
# Copy this file to .env and fill in your API keys
# You only need to configure the providers you want to use

# ==========================================
# OpenAI Configuration
# ==========================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# ==========================================
# Anthropic Configuration
# ==========================================
# Get your API key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# ==========================================
# Google Gemini Configuration
# ==========================================
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# ==========================================
# LM Studio Configuration (Local)
# ==========================================
# LM Studio runs locally - no API key needed
# Just make sure LM Studio is running with a model loaded
# Default URL is http://localhost:1234/v1
LMSTUDIO_BASE_URL=http://localhost:1234/v1

# ==========================================
# Default Provider Settings
# ==========================================
# Which provider to use by default: openai, anthropic, gemini, lmstudio
DEFAULT_PROVIDER=gemini

# Default model (leave empty to use provider's default cheap/fast model)
DEFAULT_MODEL=
